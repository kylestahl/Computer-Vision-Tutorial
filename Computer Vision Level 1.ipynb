{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision \n",
    "# Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kyle Stahl\n",
    "#### Feb. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis will walk through a (relatively) simple computer vision example on the MNIST dataset. If you are unfamililar with the MNIST data, it is a set of thousands of 28x28 pixel black and white images of handwritten numeric digits 0-9. The goal is to teach the computer to be able to recognize the digit that is written in each image. Think of this as what your ATM or mobile phone banking app is doing when you insert, or take a picture of a check. That software will locate the area of the check with the total amount, and then attempt to figure out what that amount is based of the written digits. \n",
    "\n",
    "This will require some python programming knowledge. A more complicated version of the same analysis performed in R can be found here: (http://rpubs.com/kstahl/MNIST-1). The Open CV python package is used to import the image data into numpy arrays, then pandas and Scikit-Learn are used for the data maniputlation and modeling. Links to the relavent documentation can be found within the analysis below. This analysis will also require some introductory statistics knowledge. I know some statistics courses cover logistic regression, but some do not. If you need a refresher on what logistic regression is, or if you are thinking that you know what linear regression is, but not _logistic_ watch this video at 1.5 speed: https://www.youtube.com/watch?v=nz-FrbAa8dY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change directory to where the photos are downloaded\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\kyles\\\\Downloads\\\\TrainingSet\")\n",
    "\n",
    "# OpenCV package will be used to bring images in as numpy arrays\n",
    "import cv2\n",
    "\n",
    "# Matplotlib used to show the images\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# tqdm is used to track the progress of loops\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Numpy and pandas for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn for model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Processing an Image as an Array of Numbers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `cv2.imread()` function, which will take an image file, and read the Red, Green, and Blue values into a numpy array pixel by pixel https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html. When the image is imported, it is stored in a 3-D numpy array. The first two dimensions are the height and width of the pixels of the image. The third dimension has three solts for RGB values 0-255. Since the image is grey scale, all three RGB values are equivalent. A few random pixel values are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array dimensions: (28, 28, 3)\n",
      "Some RGB values from randomly selected pixels\n",
      "[0 0 0]\n",
      "[154 154 154]\n",
      "[0 0 0]\n",
      "[12 12 12]\n",
      "[8 8 8]\n",
      "[151 151 151]\n",
      "[0 0 0]\n",
      "[16 16 16]\n",
      "[19 19 19]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"3/img_9.jpg\")\n",
    "print(\"Array dimensions: {}\".format(img.shape))\n",
    "print(\"Some RGB values from randomly selected pixels\")\n",
    "for i in [11,14,17]:\n",
    "    for j in [9,12,21]:\n",
    "        print(img[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will show you what the picutre looks like with its 28x28 pixels in RGB format. Now hopefully you have a better visualization of what we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQpxiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fe73f03f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is just a grey scale image, we do not need all three RGB dimensions, we can just use one color. In other words, we can represent each pixel with one number which will tell how much **white** is in each pixel. Since all of the RGB values are the same for each pixel, we can just average the those for each pixel and it will not change the image. Below, I print out the exact same pixel values and image to show that it is unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array dimensions: (28, 28)\n",
      "0.0\n",
      "154.0\n",
      "0.0\n",
      "12.0\n",
      "8.0\n",
      "151.0\n",
      "0.0\n",
      "16.0\n",
      "19.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fe790cb080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flat = img.mean(axis=2)\n",
    "print(\"Array dimensions: {}\".format(flat.shape))\n",
    "for i in [11,14,17]:\n",
    "    for j in [9,12,21]:\n",
    "        print(flat[i,j])\n",
    "        \n",
    "plt.imshow(flat,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to flatten the pixels of this image so that it can be organized in a 1 x 784 row, instead of a 28 x 28 matrix. That way we will be able to stack all of the image data in one dataframe. Our training data has 42,000 images, and each image has 784 pixels. So the resulting data frame will be 42,000 rows by 784 columns, and each value will represent the intensity of a pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array dimensions: (784,)\n"
     ]
    }
   ],
   "source": [
    "row = flat.flatten()\n",
    "print(\"Array dimensions: {}\".format(row.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing All the Images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to import all of the images, and keep track of which images have which digit. I downloaded the pictures in jpg format from https://www.kaggle.com/scolianni/mnistasjpg/data. They are in a folder locally on my computer, and each digit has it's own subfolder. So all of 0's are separated from the 1's and 2's and so on and so forth. \n",
    "\n",
    "Below I coded two different ways to import the images. The first looks shorter, it would be considered more of a depth-first-search. It goes into each folder one at a time and imports all of the images from that sub-folder, then it moves on to the next. In other words, it imports all the 0's, then moves onto the 1's, then 2's... and each time it switches folders it tracks what digit it is importing. The second way looks like more lines of code, but executes in a shorter time. It goes image-by-image and looks for each image through all of the folders.\n",
    "\n",
    "Either way, I found it was much faster to initialize an array of zeros before starting since you already know what the final size is going to be, rather then continuously appending to a dataframe or array. In both cases, we follow the image preprocessing steps above. \n",
    "\n",
    "I put progress bars for the loops with the `tqdm` package to be able to visualize the progress https://pypi.python.org/pypi/tqdm. The first method has 10 progress bars because each folder is searched independently, the second only has one because all the folders are being searched at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:11<00:00, 3517.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:14<00:00, 2874.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:14<00:00, 2970.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:14<00:00, 2912.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:11<00:00, 3639.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:10<00:00, 4100.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:12<00:00, 3294.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:11<00:00, 3739.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:08<00:00, 5137.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 42000/42000 [00:11<00:00, 3791.61it/s]\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros([42000,784])\n",
    "label = []\n",
    "for i in range(10):\n",
    "    for j in tqdm(range(42000)):\n",
    "        img = cv2.imread(str(i) + \"/img_\" + str(j) + \".jpg\")\n",
    "        if img is not None:\n",
    "            data[j,:] = img.mean(axis = 2).flatten()\n",
    "            label.append(i)  \n",
    "            \n",
    "# Here there are 10 progress bars because we loop through\n",
    "# the ten digits individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 42000/42000 [01:20<00:00, 522.74it/s]\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros([42000,784])\n",
    "label = []\n",
    "for i in tqdm(range(42000)):\n",
    "    img = cv2.imread(\"0/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(0)\n",
    "        continue\n",
    "    img = cv2.imread(\"1/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(1)\n",
    "        continue\n",
    "    img = cv2.imread(\"2/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(2)\n",
    "        continue\n",
    "    img = cv2.imread(\"3/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(3)\n",
    "        continue\n",
    "    img = cv2.imread(\"4/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(4)\n",
    "        continue\n",
    "    img = cv2.imread(\"5/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(5)\n",
    "        continue\n",
    "    img = cv2.imread(\"6/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(6)\n",
    "        continue    \n",
    "    img = cv2.imread(\"7/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(7)\n",
    "        continue\n",
    "    img = cv2.imread(\"8/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(8)\n",
    "        continue\n",
    "    img = cv2.imread(\"9/img_\" + str(i) + \".jpg\")\n",
    "    if img is not None:\n",
    "        data[i,:] = img.mean(axis = 2).flatten()\n",
    "        label.append(9)\n",
    "        continue\n",
    "        \n",
    "# Now there is only one progress bar because we are searching through all the folders at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put the results in a 42,000 x 784 data frame. One row for each image and one column for each pixel. If you are not familiar with data frames, you can check out the official pandas introduction here: https://pandas.pydata.org/pandas-docs/stable/10min.html. Or watch this short video which describes data frames in the R programming language, but the concept is the exact same. https://www.youtube.com/watch?v=9f2g7RN5N0I. Then we print out 10 rows just to see what our data is currently looking like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8     9   ...   774  775   776  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0 ...   0.0  0.0   0.0   \n",
       "1  3.0  0.0  0.0  3.0  7.0  3.0  0.0  3.0  0.0  11.0 ...   0.0  0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0 ...   0.0  0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  2.0  8.0  0.0  0.0   3.0 ...   0.0  0.0  13.0   \n",
       "4  0.0  4.0  6.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0 ...   0.0  0.0   0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0   0.0 ...   0.0  0.0   0.0   \n",
       "6  4.0  0.0  0.0  2.0  2.0  0.0  0.0  1.0  5.0   1.0 ...   0.0  0.0   0.0   \n",
       "7  0.0  0.0  4.0  8.0  1.0  0.0  0.0  3.0  0.0   0.0 ...   8.0  0.0   0.0   \n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0   3.0 ...   0.0  0.0   0.0   \n",
       "9  0.0  2.0  0.0  0.0  5.0  2.0  0.0  0.0  0.0   3.0 ...   0.0  0.0   0.0   \n",
       "\n",
       "    777  778  779  780  781  782  783  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  11.0  1.0  6.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7   6.0  3.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.Series(label)\n",
    "X = pd.DataFrame(data)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Predictive Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is cleaned, we can start modeling. The first step is to split our images into a training and a testing set. We could go through and randomly select images ourselves, but luckily the people who developed scikit-learn made a function to do this for us. Check out how it works here: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html We initialize a random state so we get the same train-test split each time we run it, and I decided on having 60% in the training and 40% in the test set. No real science behind that decision, sometimes you just need to choose something; 70/30 and 80/20 would've worked just as well. Generally, you want more in the training set than the test set, and this training takes a significant amount of time so I chose to have a relatively smaller training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.40, random_state=1848)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set X variables: (29400, 784)\n",
      "Train Set Y variables: (29400,)\n",
      "Test Set X variables: (12600, 784)\n",
      "Test Set Y variables: (12600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set X variables: {}\".format(Xtrain.shape))\n",
    "print(\"Train Set Y variables: {}\".format(Ytrain.shape))\n",
    "print(\"Test Set X variables: {}\".format(Xtest.shape))\n",
    "print(\"Test Set Y variables: {}\".format(Ytest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train 10 separate logistic regression models. Each one can predict binary 0 or 1 values. Therefore, we need to transform our dependent `Y` variable into 10 different dependent variables, each one containing only 0's and 1's. For example, the variable `sevens` will contain an array of 0's and 1's, a `1` represents that the digit written in that image is a _7_, a `0` would represent any other digit image. And likewise for the other images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeros  = (Ytrain == 0)\n",
    "ones   = (Ytrain == 1)\n",
    "twos   = (Ytrain == 2)\n",
    "threes = (Ytrain == 3)\n",
    "fours  = (Ytrain == 4)\n",
    "fives  = (Ytrain == 5)\n",
    "sixs   = (Ytrain == 6)\n",
    "sevens = (Ytrain == 7)\n",
    "eights = (Ytrain == 8)\n",
    "nines  = (Ytrain == 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to initialize all ten of the models. This doesn't do anything besides create an object that will later be used train, store, and utilize the models. There are many parameters that can be passed for this initialization; I chose to specify a solver that is faster on larger datasets. And a max number of iterations was just set to a realtively large number that did not take to long to run. None of the models converged at this maximum. Check out the documentation for more information. http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iszero = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "isone = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "istwo = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "isthree = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "isfour = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "isfive = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "issix = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "isseven = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "iseight = LogisticRegression(solver = 'saga', max_iter = 1000)\n",
    "isnine = LogisticRegression(solver = 'saga', max_iter = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have initialized the models, we can train each model with the training set, and the binary vectors created above. This will find the optimal parameters for each model to predict if an image is a 0, or 3, or 8, or so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kyles\\.conda\\envs\\Python3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='saga', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iszero.fit(Xtrain,zeros)\n",
    "isone.fit(Xtrain,ones)\n",
    "istwo.fit(Xtrain,twos)\n",
    "isthree.fit(Xtrain,threes)\n",
    "isfour.fit(Xtrain,fours)\n",
    "isfive.fit(Xtrain,fives)\n",
    "issix.fit(Xtrain,sixs)\n",
    "isseven.fit(Xtrain,sevens)\n",
    "iseight.fit(Xtrain,eights)\n",
    "isnine.fit(Xtrain,nines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the models are trained, we are going to test the results on the test set to find our accuracy. For each observation in the test set, we run the image through all ten models. This will give us the probability that an image is a 0, or 1, or 2 and so on. We organize that information into a 2-D numpy where the probability that the image is a `0` is at the zeroth index, `1` at the first index, all the way up to 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12600, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = np.array([iszero.predict_proba(Xtest)[:,1], \n",
    "                  isone.predict_proba(Xtest)[:,1],\n",
    "                  istwo.predict_proba(Xtest)[:,1],\n",
    "                  isthree.predict_proba(Xtest)[:,1],\n",
    "                  isfour.predict_proba(Xtest)[:,1],\n",
    "                  isfive.predict_proba(Xtest)[:,1],\n",
    "                  issix.predict_proba(Xtest)[:,1],\n",
    "                  isseven.predict_proba(Xtest)[:,1],\n",
    "                  iseight.predict_proba(Xtest)[:,1],\n",
    "                  isnine.predict_proba(Xtest)[:,1]]).T\n",
    "\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we will get for each image. Below is an example for the 73rd image. We can see that most of the probabilities are very very small, except for the number at index 0 which is 0.9999. This gives us a good indication that the image contains a zero. The next smallest number is at the 8th index with a 0.07. This makes sense because 0's and 8's look somewhat similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.99997637e-01   3.36567381e-18   5.37434716e-04   6.14828265e-08\n",
      "   6.22878777e-11   1.65356990e-08   1.17201096e-01   1.02919072e-06\n",
      "   4.21504601e-02   5.21727754e-09]\n"
     ]
    }
   ],
   "source": [
    "print(probs[73,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can print out that image and see it is in fact a zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fe793f5588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xtest.iloc[73,:].values.reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that logic, we find the index that has the maximum value for each image with the numpy `argmax()` function. This will give us the final prediction for each element in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12600,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(probs, axis = 1)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can calculate our accuracy, which we find by taking the total number of predictions that were correct, out of the total number of images in the test set. And we get a final accuracy of 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the final model is: 0.9106\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the final model is: {}\".format((predictions == Ytest).mean().round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Next Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is not so good compared to other algorithms on this problem, but it is a good start. There are a lot of things we did not do in this example to keep things (relatively) simple, but they will be covered in the next tutorial. That can be found here: (http://kyle-stahl-mn.com/computer-vision-2). Some of these step will included: data scaling or normalization, cross validation, and grid search parameter selection. More of the focus will be on the machine learning process, instead of importing the images. We will also explore the relationship between this model, and a simple neural network. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
